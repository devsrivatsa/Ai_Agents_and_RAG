{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "import uuid\n",
    "from langsmith import client\n",
    "from langchain import hub\n",
    "from langsmith.schemas import Example, Run\n",
    "from langsmith.evaluation import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomic137M_embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "sample = nomic137M_embeddings.embed_query(\"Hello world\")\n",
    "type(sample), len(sample), sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of URLs to load documents from\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=20\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "#add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents = doc_splits,\n",
    "    collection_name = \"rag-chroma\",\n",
    "    embedding = nomic137M_embeddings\n",
    ")\n",
    "retriever = vectorstore.as_retriever(k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3\", format=\"json\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a teacher grading a quiz. You will be given:\n",
    "    1/ a QUESTION\n",
    "    2/ a FACT provided by the student\n",
    "    \n",
    "    You are grading RELEVANCE_RECALL:\n",
    "    A score 1 means ANY of the statements in the FACT are relevant to the QUESTION.\n",
    "    A score 0 means that NONE of the statements in the FACT are relevant to the QUESTION.\n",
    "    1 is the highest (best) score. 0 is the lowest score you can award.\n",
    "    \n",
    "    Explain your reasoning in a step-by-step manner. Ensure your reasoning and conclusion are correct.\n",
    "    \n",
    "    Avoid simply stating the correct answer at the outset.\n",
    "    \n",
    "    Question: {question} \\n\n",
    "    Fact: \\n\\n {documents} \\n\\n\n",
    "    \n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\"\"\",\n",
    "    input_variables = [\"question\", \"documents\"]\n",
    ")\n",
    "\n",
    "retrieval_grder = prompt | llm | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"agent memory\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_text = docs[1].page_content\n",
    "print(retrieval_grder.invoke(input={\"question\": question, \"documents\": doc_text}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_prompt = PromptTemplate(\n",
    "    template = \"\"\"You are an assistant for question-answering tasks.\n",
    "    \n",
    "    Use the following documents to answer the question.\n",
    "    \n",
    "    If you don't know the answer, just say that you don't know.\n",
    "    \n",
    "    Use three sentences maximum and keep the answer concise:\n",
    "    Question: {question}\\n\n",
    "    Documents: \\n{documents}\\n\n",
    "    Answer:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "rag_chain = rag_prompt | llm | StrOutputParser()\n",
    "generation = rag_chain.invoke({\"documents\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_tool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        search: whether to add search\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "    question: str\n",
    "    generation: str\n",
    "    search: bool\n",
    "    documents: List[str]\n",
    "    steps: List[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(question)\n",
    "    steps = state[\"steps\"]\n",
    "    steps.append(\"retrieve_documents\")\n",
    "    return {\"documents\": documents, \"question\": question, \"steps\": steps}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = rag_chain.invoke({\"documents\": documents, \"question\": question})\n",
    "    steps = state[\"steps\"]\n",
    "    steps.append(\"generate_answer\")\n",
    "    return {\n",
    "        \"documents\": documents,\n",
    "        \"question\": question,\n",
    "        \"generation\": generation,\n",
    "        \"steps\": steps\n",
    "    }\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    steps = state[\"steps\"]\n",
    "    steps.append(\"grade_document_retrieval\")\n",
    "    filtered_docs = []\n",
    "    search = \"No\"\n",
    "    for d in documents:\n",
    "        score = retrieval_grder.invoke({\"question\": question, \"documents\": d.page_content})\n",
    "        grade = score[\"score\"]\n",
    "        if grade == \"Yes\":\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            search = \"Yes\"\n",
    "            continue\n",
    "    return {\n",
    "        \"documents\": filtered_docs,\n",
    "        \"question\": question,\n",
    "        \"search\": search,\n",
    "        \"steps\": steps\n",
    "    }\n",
    "\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based on the re-phrased question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with appended web results\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    steps = state[\"steps\"]\n",
    "    steps.append(\"web_search\")\n",
    "    web_results = web_search_tool.invoke({\"query\": question})\n",
    "    documents.extend(\n",
    "        [\n",
    "            Document(page_content=d[\"content\"], metadata = {\"url\": d[\"url\"]}) \n",
    "            for d in web_results\n",
    "        ]\n",
    "    )\n",
    "    return {\"doucments\": documents, \"question\": question, \"steps\": steps}\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "    search = state[\"search\"]\n",
    "    if search == \"Yes\":\n",
    "        return \"Search\"\n",
    "    else:\n",
    "        return \"Generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J5NKY4KAACRHK708GQ9NADBV",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "#nodes\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"web_search\", web_search)\n",
    "\n",
    "#build graph\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"Search\": \"web_search\",\n",
    "        \"Generate\": \"generate\"\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"web_search\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "crag_graph = workflow.compile()\n",
    "display(Image(crag_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J5NMA3C5A1GH1BE3STBFFDB9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_custom_agent_local_answer(example: dict):\n",
    "    config = {\"configuration\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "    state_dict = crag_graph.invoke(\n",
    "        {\n",
    "            \"question\": example[\"input\"],\n",
    "            \"steps\": []\n",
    "        },\n",
    "        config\n",
    "    )\n",
    "    return {\"response\": state_dict[\"generation\"], \"steps\": state_dict[\"steps\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J5NPPNS841ZBECQGH9N1TJT3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(query:str):\n",
    "    example = {\"input\": query}\n",
    "    response = predict_custom_agent_local_answer(example)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J5NPRXACQ4FBPSNAXHYNGPEC",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred(\"what is automatic prompt design ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J5P425218135WASXC523K3PB",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred(\"what is few shot prompting ? Can you give me an example ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01J5P4CPJHX2QQTTP0CW60HF7G",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
